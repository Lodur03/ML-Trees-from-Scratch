{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Felipe Lodur\n",
    "\n",
    "# Trees\n",
    "\n",
    "Implementing and experimenting Decision Tree, Bagging Trees and Random Forest.\n",
    "\n",
    "### Data Format\n",
    "- last column of the data frame must contain the label and it must also be called \"label\"\n",
    "- there should be no missing values in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(df, test_size):\n",
    "    ''' test_size can be presented as:\n",
    "            float: percentage of data to be used as test set\n",
    "            int: number of instances to b used as test set\n",
    "    '''\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "random.seed(42) # as always :p\n",
    "train_df, test_df = train_test_split(df, test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>{'Iris-virginica': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>{'Iris-virginica': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>{'Iris-virginica': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>{'Iris-setosa': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>{'Iris-virginica': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>{'Iris-virginica': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>{'Iris-versicolor': 1.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred                     proba\n",
       "28       Iris-setosa      {'Iris-setosa': 1.0}\n",
       "6        Iris-setosa      {'Iris-setosa': 1.0}\n",
       "70    Iris-virginica   {'Iris-virginica': 1.0}\n",
       "62   Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "57   Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "35       Iris-setosa      {'Iris-setosa': 1.0}\n",
       "26       Iris-setosa      {'Iris-setosa': 1.0}\n",
       "139   Iris-virginica   {'Iris-virginica': 1.0}\n",
       "22       Iris-setosa      {'Iris-setosa': 1.0}\n",
       "108   Iris-virginica   {'Iris-virginica': 1.0}\n",
       "8        Iris-setosa      {'Iris-setosa': 1.0}\n",
       "7        Iris-setosa      {'Iris-setosa': 1.0}\n",
       "23       Iris-setosa      {'Iris-setosa': 1.0}\n",
       "55   Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "59   Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "129  Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "143   Iris-virginica   {'Iris-virginica': 1.0}\n",
       "50   Iris-versicolor  {'Iris-versicolor': 1.0}\n",
       "107   Iris-virginica   {'Iris-virginica': 1.0}\n",
       "56   Iris-versicolor  {'Iris-versicolor': 1.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DecisionTree import DecisionTree\n",
    "\n",
    "dt = DecisionTree(max_depth = , min_samples = 5, impurity = 'entropy')\n",
    "dt.fit(train_df)\n",
    "dt.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(df, test_size = 20, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    ''' test_size can be presented as:\n",
    "            float: percentage of data to be used as test set\n",
    "            int: number of instances to b used as test set\n",
    "    '''\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth = 3, min_samples = 2, impurity = 'entropy'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        assert impurity in ['entropy','gini'],\"Invalid impurity method, choose 'entropy' or 'gini'\"\n",
    "        self._impurity = impurity\n",
    "    \n",
    "    # TREINAMENTO.....\n",
    "    def _check_purity(self, data):\n",
    "        \"\"\" helper \"\"\"\n",
    "        label_column = data[:, -1]\n",
    "        qty_unique_classes = len(np.unique(label_column))\n",
    "    \n",
    "        return not (qty_unique_classes - 1)\n",
    "    \n",
    "    def _classify_data(self, data):\n",
    "        \"\"\" helper \"\"\"\n",
    "        label_column = data[:, -1]\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        prevalent_class_index = counts_unique_classes.argmax()\n",
    "        classification = unique_classes[prevalent_class_index]\n",
    "\n",
    "        return unique_classes, counts_unique_classes\n",
    "    \n",
    "    def _get_potential_splits(self, data):\n",
    "        \"\"\" helper \"\"\"\n",
    "        potential_splits = {}\n",
    "        n_columns = data.shape[1]\n",
    "        \n",
    "        rolling_mean = lambda a: ((a[1:] + a[:-1])/2).tolist()\n",
    "\n",
    "        for column_index in range(n_columns - 1):        # excluding the last column which is the label\n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "\n",
    "            potential_splits[column_index] = rolling_mean(unique_values)\n",
    "\n",
    "        return potential_splits\n",
    "    \n",
    "    def _split_data(self, data, split_column, split_value):\n",
    "        \"\"\" helper \"\"\"\n",
    "        split_column_values = data[:, split_column]\n",
    "        \n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "\n",
    "        return data_below, data_above\n",
    "    \n",
    "    def _calculate_impurity(self, data):\n",
    "        \"\"\" helper \"\"\"\n",
    "        label_column = data[:, -1]\n",
    "        counts = np.unique(label_column, return_counts=True)[1] # note que np.unique so retorna labels encontrados...\n",
    "\n",
    "        probabilities = counts / counts.sum()\n",
    "        if self._impurity == 'gini':\n",
    "            impurity = - probabilities @ np.log2(probabilities) # ... assim não vai existir 0 * inf, o que no lim daria 0 mesmo\n",
    "        else: # entropy otherwise\n",
    "            impurity = probabilities @ (1-probabilities)\n",
    "            \n",
    "        return impurity\n",
    "    \n",
    "    \n",
    "    def _calculate_overall_impurity(self, data_below, data_above):\n",
    "        \"\"\" helper \"\"\"\n",
    "        lens_ba = np.array([len(data_below), len(data_above)])\n",
    "        probs_ba = lens_ba / lens_ba.sum()\n",
    "\n",
    "        entropy_ba = np.array([self._calculate_impurity(data_below), \n",
    "                               self._calculate_impurity(data_above)])\n",
    "\n",
    "        overall_entropy =  probs_ba @ entropy_ba\n",
    "        \n",
    "        return overall_entropy\n",
    "    \n",
    "    def _determine_best_split(self, data, potential_splits):\n",
    "        \"\"\" helper \"\"\"\n",
    "        overall_entropy = 9999\n",
    "        for column_index in potential_splits:\n",
    "            for value in potential_splits[column_index]:\n",
    "                data_below, data_above = self._split_data(data, \n",
    "                                                          split_column=column_index, \n",
    "                                                          split_value=value)\n",
    "                current_overall_entropy = self._calculate_overall_impurity(data_below, \n",
    "                                                                          data_above)\n",
    "                if current_overall_entropy <= overall_entropy:\n",
    "                    overall_entropy = current_overall_entropy\n",
    "                    best_split_column = column_index\n",
    "                    best_split_value = value\n",
    "\n",
    "        return best_split_column, best_split_value\n",
    "    \n",
    "    def _stop_split(self, data, counter):\n",
    "        \"\"\"\n",
    "        helper. O nó deve parar de ser dividido?\n",
    "        incluir todas as condições para parar de dividir o nó\n",
    "        returns\n",
    "        -------\n",
    "        stop_split:\n",
    "            True: se o nó for terminal, i.e., uma das condições de parada foi atingido\n",
    "            False: se o nó for intermediário, pode ir seguir quebrando\n",
    "        \"\"\"\n",
    "        stop_split = self._check_purity(data) or (len(data) < self.min_samples) or \\\n",
    "                    (counter == self.max_depth)\n",
    "        return stop_split\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        função externa para montar a arvore\n",
    "        \"\"\"\n",
    "        self.tree_ = self._decision_tree_algorithm(df)\n",
    "    \n",
    "    def _decision_tree_algorithm(self, df, counter = 0):\n",
    "        \"\"\"\n",
    "        procedimento recursivo para montar a arvore\n",
    "        \"\"\"\n",
    "    \n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            #global COLUMN_HEADERS\n",
    "            self.column_headers = df.columns\n",
    "            data = df.values\n",
    "        else:\n",
    "            data = df           \n",
    "\n",
    "        # base cases\n",
    "        basecase_reached = self._stop_split(data, counter)\n",
    "        if basecase_reached:\n",
    "            classification, counts_unique_classes = self._classify_data(data)\n",
    "            return classification, counts_unique_classes\n",
    "\n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = self._get_potential_splits(data)\n",
    "            split_column, split_value = self._determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = self._split_data(data, split_column, split_value)\n",
    "\n",
    "            # instantiate sub-tree\n",
    "            feature_name = self.column_headers[split_column]\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            sub_tree = {question: []}\n",
    "\n",
    "            # find answers (recursion)\n",
    "            yes_answer = self._decision_tree_algorithm(data_below, counter)\n",
    "            no_answer  = self._decision_tree_algorithm(data_above, counter)\n",
    "\n",
    "            # If the answers are the same, then there is no point in asking the qestion.\n",
    "            # This could happen when the data is classified even though it is not pure\n",
    "            # yet (min_samples or max_depth base case).\n",
    "            if np.array_equal(yes_answer, no_answer):\n",
    "                sub_tree = yes_answer\n",
    "            else:\n",
    "                sub_tree[question].append(yes_answer)\n",
    "                sub_tree[question].append(no_answer)\n",
    "\n",
    "            return sub_tree\n",
    "    \n",
    "    # PREDICOES.....\n",
    "    def predict(self, df):\n",
    "        \"\"\"\n",
    "        função externa para predição. \n",
    "        percorre a arvore em busca de um nó terminal\n",
    "        \"\"\"\n",
    "        prediction = df.apply(self._classify_example, axis = 1)\n",
    "        prediction = prediction.apply(pd.Series)\n",
    "        prediction.columns = ['pred', 'proba']\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def _calc_probs(self, a):\n",
    "        \"\"\" helper, retorna vetor normalizado por L1\"\"\"\n",
    "        norm = a[1].sum()\n",
    "        res = {k: v/norm for k, v in zip(a[0], a[1])}\n",
    "        return res\n",
    "\n",
    "    def _get_most_prevalent_class(self, a):\n",
    "        \"\"\" helper, retorna a classe mais prevalente\"\"\"\n",
    "        most_prevalent_idx = a[1].argmax()\n",
    "        most_prevalent_class = a[0][most_prevalent_idx]\n",
    "        return most_prevalent_class\n",
    "    \n",
    "    def _classify_example(self, example, tree = None):\n",
    "        \"\"\" proc recursivo que retorna a classificação e as probabilidades\n",
    "        \"\"\"\n",
    "        \n",
    "        if not tree:  # prim. chamada, usar arvore inteira\n",
    "            tree = self.tree_\n",
    "        \n",
    "        question = list(tree.keys())[0]\n",
    "        feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "        # ask question\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "        # base case\n",
    "        if not isinstance(answer, dict):\n",
    "            probs = self._calc_probs(answer)\n",
    "            the_class = self._get_most_prevalent_class(answer)\n",
    "            return the_class, probs\n",
    "\n",
    "        # recursive part\n",
    "        else:\n",
    "            residual_tree = answer\n",
    "            return self._classify_example(example, residual_tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício IV: (BaggingTrees)\n",
    "\n",
    "- Criar um classificador BaggingTrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingTrees(object):\n",
    "    \n",
    "    def __init__(self, n_estimators=10, bootstrap_value=1.0, **tree_params):\n",
    "        ''' Constructor. \n",
    "                n_estimators: number of bagged trees\n",
    "                boostrap_value: sample size, either in percentages or number of samples\n",
    "                tree_params: decision tree hyperparams\n",
    "        '''\n",
    "        self._tree_params = tree_params\n",
    "        self._n_estimators = n_estimators\n",
    "        self._estimators = [DecisionTree(**tree_params) for _ in range(n_estimators)]\n",
    "        self._bootstrap_value = bootstrap_value\n",
    "        \n",
    "    def _bootstrap(self, df):\n",
    "        ''' helper: Sampling without replacement '''            \n",
    "        dados = df.values\n",
    "        samples = []\n",
    "        sample_size = self._bootstrap_value if self._bootstrap_value > 1 else int(self._bootstrap_value*len(dados))\n",
    "        for i in range(self._n_estimators):  # One sample per estimator\n",
    "            s = random.choices(dados, k = sample_size)\n",
    "            s = pd.DataFrame(s, columns=df.columns.values)\n",
    "            samples.append(s)\n",
    "                    \n",
    "        return samples\n",
    "    \n",
    "    def fit(self, df):\n",
    "        ''' Train bagged trees '''\n",
    "        samples = self._bootstrap(df)\n",
    "        for i, tree in enumerate(self._estimators):\n",
    "            tree.fit(samples[i])\n",
    "            \n",
    "    def _format_prediction(self, predictions):\n",
    "        ''' helper: Formats the predictions in a easy-to-read format '''\n",
    "        prediction = sum(predictions)/self._n_estimators # Average of predictions\n",
    "        prediction['pred'] = prediction.idxmax(axis=1)\n",
    "        cols = prediction.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        return prediction[cols]\n",
    "    \n",
    "    def predict(self, df):\n",
    "        ''' Make predictions and return the probabilities along the class with highest probability '''\n",
    "        # Make predictions on each tree\n",
    "        predictions = []\n",
    "        for tree in self._estimators:\n",
    "            pred = tree.predict(df)\n",
    "            pred = pred['proba'].apply(pd.Series).fillna(0)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return self._format_prediction(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o BaggingTrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.990703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.998060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.998060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.990703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196511</td>\n",
       "      <td>0.803489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.998060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037599</td>\n",
       "      <td>0.962401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248122</td>\n",
       "      <td>0.751878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670986</td>\n",
       "      <td>0.329014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.998060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "98   Iris-versicolor          0.0         0.998578        0.001422\n",
       "107   Iris-virginica          0.0         0.009297        0.990703\n",
       "10       Iris-setosa          1.0         0.000000        0.000000\n",
       "66   Iris-versicolor          0.0         0.998578        0.001422\n",
       "130   Iris-virginica          0.0         0.001940        0.998060\n",
       "124   Iris-virginica          0.0         0.001940        0.998060\n",
       "103   Iris-virginica          0.0         0.009297        0.990703\n",
       "77    Iris-virginica          0.0         0.196511        0.803489\n",
       "122   Iris-virginica          0.0         0.001940        0.998060\n",
       "91   Iris-versicolor          0.0         0.998578        0.001422\n",
       "149   Iris-virginica          0.0         0.037599        0.962401\n",
       "55   Iris-versicolor          0.0         0.998578        0.001422\n",
       "129   Iris-virginica          0.0         0.248122        0.751878\n",
       "35       Iris-setosa          1.0         0.000000        0.000000\n",
       "72   Iris-versicolor          0.0         0.670986        0.329014\n",
       "24       Iris-setosa          1.0         0.000000        0.000000\n",
       "64   Iris-versicolor          0.0         0.998578        0.001422\n",
       "136   Iris-virginica          0.0         0.001940        0.998060\n",
       "37       Iris-setosa          1.0         0.000000        0.000000\n",
       "79   Iris-versicolor          0.0         0.998578        0.001422"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingTrees(n_estimators=100, bootstrap_value=0.9,           # bagging params\n",
    "                   max_depth=3, min_samples=20, impurity='entropy') # **tree_params\n",
    "clf.fit(train_df)\n",
    "clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
